{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "N_steps = 5000\n",
    "beta_max = 1.35\n",
    "beta_min = 0.1\n",
    "beta_model = np.linspace(beta_min, beta_max, N_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlims = np.array([[beta_min,beta_max],\n",
    "                  [0.4,1.3],\n",
    "                  [0.9,1.2]])\n",
    "\n",
    "ylims = np.array([[0,0],            # Placeholder for beta\n",
    "                  [-2,0],           # Energy\n",
    "                  [0,4],            # Energy squared !!(multiply by L**2)!!\n",
    "                  [-0.02,0.02],     # Magnetization\n",
    "                  [0,3],            # Magnetization squared\n",
    "                  [0,0.25],         # Absolute magnetization\n",
    "                  [0,2.5],          # Specific heat\n",
    "                  [0,0.5],          # Susceptibility\n",
    "\n",
    "\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObs(fname, qty_number):\n",
    "    df = pd.read_csv(fname)\n",
    "    betas = df[\"Beta\"]\n",
    "    header = list(df)[qty_number]\n",
    "    observable = df[header]\n",
    "    obs_interp = make_interp_spline(betas,observable,k=3)\n",
    "\n",
    "    beta_model = np.linspace(0.1,beta_max,N_steps)\n",
    "    obs_model = obs_interp(beta_model)\n",
    "    return obs_model\n",
    "\n",
    "def getlastFE(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    betas = df[\"Beta\"]\n",
    "    FE = -1*df[\"Free Energy\"]/df[\"Beta\"] # need to manipulate F a little, based on what is calculated in C++\n",
    "    \n",
    "    FE_interp = make_interp_spline(betas,FE,k=3)\n",
    "    beta_model = np.linspace(0.1,beta_max,N_steps)\n",
    "    FE_model = FE_interp(beta_model)\n",
    "    return FE_model[-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnbiasedEstimate(kappa,L,R,mode,quantity):\n",
    "    # This function returns the unbiased estimator for an observable, as well as its standard error which is found using the bootstrap method.\n",
    "    kappastr = f\"{kappa:.2f}\"\n",
    "    modestr = \"Two-Replica_Method\" if (mode == \"t\") else \"Wolff_Method\"\n",
    "    dirpath = f\"/Users/shanekeiser/Downloads/production-run/{modestr}/{kappastr}_kappa/{L}_L/{R}_R\"\n",
    "    filepattern = f\"emcx_data_*\"\n",
    "    files = glob.glob(f\"{dirpath}/{filepattern}\")\n",
    "    print(f\"No. of datasets = {len(files)}\")\n",
    "    beta_model = np.linspace(0.1,2,N_steps)   \n",
    "    df_example = pd.read_csv(files[0])\n",
    "    header = list(df_example)[quantity]\n",
    "    if L == 96:\n",
    "        tail = 18\n",
    "    else:\n",
    "        tail = 1\n",
    "\n",
    "    if quantity != 18 and quantity != 6:\n",
    "\n",
    "        obs_matrix = np.zeros(shape = (len(files), N_steps))\n",
    "        FE_weights = np.zeros(shape = (len(files), N_steps))\n",
    "        FE_weight_denoms = np.zeros(shape = N_steps)\n",
    "        FE_interp = np.zeros(shape = (len(files), N_steps))\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            df = pd.read_csv(files[i])\n",
    "            df.drop(df.tail(tail).index,inplace=True)\n",
    "            betas = np.array(df[\"Beta\"])\n",
    "            observable = df[header]\n",
    "            FE = df[\"Free Energy\"] ### DIVIDE BY NUMBER OF SPINS TO MAKE NUMBERS MANAGEABLE --> Is this even OK to do? probably yes just to get weightings\n",
    "            # print(FE)\n",
    "            obs_spline = make_interp_spline(betas, observable, k=3)\n",
    "            FE_spline = make_interp_spline(betas, FE, k=3)\n",
    "            obs_interp = obs_spline(beta_model)\n",
    "            obs_matrix[i,:] = obs_interp\n",
    "            FE_interp[i,:] = FE_spline(beta_model)\n",
    "            for j in range(N_steps):\n",
    "                FE_weights[i,j] = np.exp(FE_interp[i,j] - max(FE_interp[:,j]))\n",
    "                FE_weight_denoms[j] += FE_weights[i,j]\n",
    "        # print(FE_weights[50,:])\n",
    "    \n",
    "        for i in range(N_steps):\n",
    "            FE_weights[:,i] /= FE_weight_denoms[i]\n",
    "        \n",
    "        unbiased_obs = np.zeros(N_steps)\n",
    "        for i in range(len(files)):\n",
    "            unbiased_obs += obs_matrix[i,:] * FE_weights[i,:]\n",
    "        \n",
    "    if quantity == 6:\n",
    "\n",
    "        ene_matrix = np.zeros(shape = (len(files), N_steps))\n",
    "        ene_sq_matrix = np.zeros(shape = (len(files), N_steps))\n",
    "        obs_matrix = np.zeros(shape = (len(files), N_steps))\n",
    "        FE_weights = np.zeros(shape = (len(files), N_steps))\n",
    "        FE_weight_denoms = np.zeros(shape = N_steps)\n",
    "        FE_interp = np.zeros(shape = (len(files), N_steps))\n",
    "        for i in range(len(files)):\n",
    "            df = pd.read_csv(files[i])\n",
    "            df.drop(df.tail(tail).index,inplace=True)\n",
    "            betas = np.array(df[\"Beta\"])\n",
    "            energy = df[\"Energy\"]\n",
    "            energy_sq = df[\"Energy Squared\"]\n",
    "            FE = df[\"Free Energy\"] ### DIVIDE BY NUMBER OF SPINS TO MAKE NUMBERS MANAGEABLE --> Is this even OK to do? probably yes just to get weightings\n",
    "            # print(FE)\n",
    "            ene_spline = make_interp_spline(betas, energy, k=3)\n",
    "            ene_sq_spline = make_interp_spline(betas, energy_sq, k=3)\n",
    "            FE_spline = make_interp_spline(betas, FE, k=3)\n",
    "            ene_interp = ene_spline(beta_model)\n",
    "            ene_sq_interp = ene_sq_spline(beta_model)\n",
    "            ene_matrix[i,:] = ene_interp\n",
    "            ene_sq_matrix[i,:] = ene_sq_interp\n",
    "            obs_matrix[i,:] = (ene_sq_interp - (ene_interp*L)**2)*beta_model**2\n",
    "            FE_interp[i,:] = FE_spline(beta_model)\n",
    "\n",
    "            for j in range(N_steps):\n",
    "                FE_weights[i,j] = np.exp(FE_interp[i,j] - max(FE_interp[:,j]))\n",
    "                FE_weight_denoms[j] += FE_weights[i,j]\n",
    "    \n",
    "        for i in range(N_steps):\n",
    "            FE_weights[:,i] /= FE_weight_denoms[i]\n",
    "        \n",
    "        unbiased_obs = np.zeros(N_steps)\n",
    "        unbiased_ene = np.zeros(N_steps)\n",
    "        unbiased_ene_sq = np.zeros(N_steps)\n",
    "        for i in range(len(files)):\n",
    "            unbiased_ene += ene_matrix[i,:] * FE_weights[i,:]\n",
    "            unbiased_ene_sq += ene_sq_matrix[i,:] * FE_weights[i,:]\n",
    "            \n",
    "        unbiased_obs = (unbiased_ene_sq - (unbiased_ene*L)**2)*beta_model**2\n",
    "        \n",
    "\n",
    "    ### Bootstrap method\n",
    "    B = 100\n",
    "\n",
    "    \n",
    "    bootstrap_obs = np.zeros(shape = (B,N_steps))\n",
    "    se_obs_bootstrap = np.zeros(shape = N_steps)\n",
    "    bootmean_std = np.zeros(len(unbiased_obs))\n",
    "    for i in range(N_steps):\n",
    "        sample = obs_matrix[:,i]\n",
    "        boot_means = []\n",
    "        for _ in range(B):\n",
    "            bootsample = np.random.choice(sample,size=len(sample), replace=True)\n",
    "            boot_means.append(bootsample.mean())\n",
    "        bootmean_std[i] = np.std(boot_means,ddof = 1)\n",
    "    se_obs_bootstrap = bootmean_std\n",
    "    \n",
    "    return unbiased_obs, se_obs_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLocalMaxima(ue, se):\n",
    "\n",
    "    for i in range(1,N_steps-1):\n",
    "        if ue[i] > ue[i-1] and ue[i] >ue[i+1] and beta_model[i] < 1.25:\n",
    "            print(f\"{ue[i]} +/- {se[i]}, beta = {beta_model[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnbiasedFE(kappa,L,R,mode):\n",
    "    kappastr = f\"{kappa:.2f}\"\n",
    "    modestr = \"Two-Replica_Method\" if (mode == \"t\") else \"Wolff_Method\"\n",
    "    dirpath = f\"/Users/shanekeiser/Downloads/production-run/{modestr}/{kappastr}_kappa/{L}_L/{R}_R\"\n",
    "    filepattern = f\"emcx_data_*\"\n",
    "    files = glob.glob(f\"{dirpath}/{filepattern}\")\n",
    "    beta_model = np.linspace(0.1,2,N_steps)   \n",
    "    FE_interp_vals = np.empty(shape = (len(files), N_steps))\n",
    "    unbiased_FE = np.empty(N_steps)\n",
    "    for i in range(len(files)):\n",
    "        # print(files[i])\n",
    "        df = pd.read_csv(files[i])\n",
    "        betas = df[\"Beta\"][:-3]\n",
    "        FE = df[\"Free Energy\"][:-3] # need to manipulate F a little, based on what is calculated in C++\n",
    "        FE_interp = make_interp_spline(betas,FE,k=3)\n",
    "        FE_model = FE_interp(beta_model)\n",
    "        FE_interp_vals[i,:] = FE_model\n",
    "    \n",
    "    for i in range(N_steps):\n",
    "        # unbiased_FE[i] = np.log((1/len(files))*np.sum(np.exp(FE_interp_vals[:,i]))) # Has overflow from too large numbers\n",
    "        unbiased_FE[i] = -np.log(len(files)) + np.max(FE_interp_vals[:,i]) + np.log(np.sum(np.exp(FE_interp_vals[:,i] - np.max(FE_interp_vals[:,i]))))\n",
    "        unbiased_FE[i] *= -1/beta_model[i]\n",
    "        unbiased_FE[i]\n",
    "\n",
    "    ### Bootstrap method\n",
    "    ### Bootstrap method\n",
    "    B = 100\n",
    "\n",
    "    \n",
    "    bootstrap_obs = np.zeros(shape = (B,N_steps))\n",
    "    se_FE_bootstrap = np.zeros(shape = N_steps)\n",
    "    bootmean_std = np.zeros(len(unbiased_FE))\n",
    "    for i in range(N_steps):\n",
    "        sample = FE_interp_vals[:,i]\n",
    "        boot_means = []\n",
    "        for _ in range(B):\n",
    "            bootsample = np.random.choice(sample,size=len(sample), replace=True)\n",
    "            boot_means.append(bootsample.mean())\n",
    "        bootmean_std[i] = np.std(boot_means,ddof = 1)\n",
    "    se_FE_bootstrap = bootmean_std\n",
    "    # print(B)\n",
    "    # N_samples = 30\n",
    "\n",
    "    # bootstrap_obs = np.zeros(shape = (B,N_steps))\n",
    "    # se_obs_bootstrap = np.zeros(shape = N_steps)\n",
    "\n",
    "    # for i in range(B):\n",
    "    #     for j in range(N_steps):\n",
    "    #         for k in range(N_samples):\n",
    "    #             r = np.random.randint(0,len(files))\n",
    "    #             bootstrap_obs[i,j] += FE_interp_vals[r,j]\n",
    "    # bootstrap_obs /= N_samples\n",
    "\n",
    "    # # print(bootstrap_obs)\n",
    "    # for i in range(N_steps):\n",
    "    #     se_obs_bootstrap[i] = np.sqrt((np.std(bootstrap_obs[:,i])**2)/(B-1))\n",
    "    # # print(B)\n",
    "    return unbiased_FE, se_FE_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWrappingQuantities(kappa,L,R):\n",
    "    kappa = 0.6\n",
    "    L = 48\n",
    "    R = 16000\n",
    "    # df_example = pd.read_csv(files[0])\n",
    "    # header = list(df_example)[quantity]\n",
    "    # print(header)\n",
    "    mode = \"t\"\n",
    "    modestr = \"Two Replica\" if (mode == \"t\") else \"Wolff\"\n",
    "\n",
    "    unbiased_xbarzbar, se_xbarzbar = getUnbiasedEstimate(kappa = kappa, L = L, R = R, mode = mode, quantity = 10)\n",
    "    unbiased_xbarz, se_xbarz = getUnbiasedEstimate(kappa = kappa, L = L, R = R, mode = mode, quantity = 19)\n",
    "    unbiased_xzbar, se_xzbar = getUnbiasedEstimate(kappa = kappa, L = L, R = R, mode = mode, quantity = 20)\n",
    "    unbiased_xz, se_xz = getUnbiasedEstimate(kappa = kappa, L = L, R = R, mode = mode, quantity = 21)\n",
    "\n",
    "    unbiased_total = unbiased_xbarzbar + unbiased_xbarz + unbiased_xzbar + unbiased_xz\n",
    "    se_total = se_xbarzbar + se_xbarz + se_xzbar + se_xz\n",
    "\n",
    "    # Customize plot appearance\n",
    "    plt.rc('text', usetex=False)  # Use LaTeX for all text\n",
    "    plt.rc('font', family='serif', size=10)  # Use serif fonts with size 10\n",
    "    plt.rc('axes', labelsize=12)  # Axis label size\n",
    "    plt.rc('legend', fontsize=10)  # Legend font size\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(7.5, 6))  # Adjust the figure size for the journal aspect ratio\n",
    "\n",
    "    from matplotlib.cm import get_cmap\n",
    "    colors = np.array([\"#fa0707\", \"#050505\", \"#30fc03\", \"#0207fa\", \"#f757f2\", \"#0dffef\", \"#ffaa0d\"])\n",
    "    markers = [\"x\", \"o\", \"^\", \"s\", \"*\", \"3\"]\n",
    "\n",
    "\n",
    "\n",
    "    ax1.errorbar(beta_model, unbiased_xbarzbar, se_xbarzbar,\n",
    "                linewidth=0, elinewidth=0.8, \n",
    "                marker=markers[0], markersize=2, \n",
    "                color=colors[0], ecolor=\"black\", \n",
    "                label=r\"$P_{\\bar{x}\\bar{z}}$\")\n",
    "\n",
    "    ax1.errorbar(beta_model, unbiased_xbarz, se_xbarz,\n",
    "                linewidth=0, elinewidth=0.8, \n",
    "                marker=markers[1], markersize=2, \n",
    "                color=colors[1], ecolor=\"black\", \n",
    "                label=r\"$P_{\\bar{x}z}$\")\n",
    "\n",
    "    ax1.errorbar(beta_model, unbiased_xzbar, se_xzbar,\n",
    "                linewidth=0, elinewidth=0.8, \n",
    "                marker=markers[2], markersize=2, \n",
    "                color=colors[2], ecolor=\"black\", \n",
    "                label=r\"$P_{x\\bar{z}}$\")\n",
    "\n",
    "    ax1.errorbar(beta_model, unbiased_xz, se_xz,\n",
    "                linewidth=0, elinewidth=0.8, \n",
    "                marker=markers[3], markersize=2, \n",
    "                color=colors[3], ecolor=\"black\", \n",
    "                label=r\"$P_{xz}$\")\n",
    "\n",
    "    ax1.errorbar(beta_model, unbiased_total, se_total,\n",
    "                linewidth=0, elinewidth=0.8, \n",
    "                marker=markers[4], markersize=2, \n",
    "                color=colors[4], ecolor=\"black\", \n",
    "                label=r\"Total\")\n",
    "            \n",
    "\n",
    "\n",
    "    # Axis labels\n",
    "    ax1.set_xlabel(r\"Inverse temperature $\\beta$\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Wrapping probabilities\", fontsize=12)\n",
    "\n",
    "    # Limits and grid\n",
    "    ax1.set_xlim(0.2, 1.4)\n",
    "    ax1.set_ylim(0,1.05)\n",
    "\n",
    "    ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Title with LaTeX formatting\n",
    "    # ax1.set_title(rf\"Unbiased Estimator for wrapping probabilities with Standard Error\" +f\"\\n\"\n",
    "    #               + rf\"$\\kappa = {kappa}$, $L = {L}$, $R = {R}$, {modestr}\", fontsize=11)\n",
    "\n",
    "    # Legend\n",
    "    ax1.legend(loc='center right', frameon=True, markerscale = 2, prop={'size': 11})\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    from datetime import date\n",
    "    datestr = date.today().strftime(\"%d%b%y\")\n",
    "    descriptor = f\"wrapping-probs-{modestr}\"\n",
    "    print(datestr)\n",
    "    if kappa == 0.6:\n",
    "        kappafilestr = \"k-0-6\"\n",
    "    elif kappa == 0:\n",
    "        kappafilest = \"k-0\"\n",
    "    plt.savefig(f\"/Users/shanekeiser/Documents/ANNNI/figures/{datestr}_{descriptor}_{kappafilestr}_L-{L}_R-{R}.png\", dpi=300)  # Save in high resolution\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparePopSize(kappa,L,R_vals):\n",
    "    kappa = 0.6\n",
    "    L = 48\n",
    "    R = 1600\n",
    "    quantity = 6\n",
    "    mode = \"t\"\n",
    "    modestr = \"Two Replica Method\" if (mode == \"t\") else \"Wolff Method\"\n",
    "    modestr = \"Two-Replica_Method\" if (mode == \"t\") else \"Wolff_Method\"\n",
    "    dirpath = f\"/Users/shanekeiser/Downloads/production-run/{modestr}/{kappastr}_kappa/{L}_L/{R}_R\"\n",
    "    filepattern = f\"emcx_data_*\"\n",
    "    files = glob.glob(f\"{dirpath}/{filepattern}\")\n",
    "    # print(files)\n",
    "    df_example = pd.read_csv(files[0])\n",
    "    header = list(df_example)[quantity]\n",
    "    print(header)\n",
    "\n",
    "\n",
    "    R_vals = np.array([80,800,1600,16000]) # R*S = 160000, epsilon = 0.1\n",
    "\n",
    "    unbiased_observables = np.empty(shape = (N_steps,len(R_vals)))\n",
    "    standard_errors = np.empty(shape = (N_steps,len(R_vals)))\n",
    "    for i in range(len(R_vals)):\n",
    "        unbiased_observables[:,i], standard_errors[:,i] = getUnbiasedEstimate(kappa = kappa, L = L, R = R_vals[i], mode = mode, quantity = quantity)\n",
    "    \n",
    "     # Customize plot appearance\n",
    "    plt.rc('text', usetex=False)  # Use LaTeX for all text\n",
    "    plt.rc('font', family='serif', size=10)  # Use serif fonts with size 10\n",
    "    plt.rc('axes', labelsize=12)  # Axis label size\n",
    "    plt.rc('legend', fontsize=10)  # Legend font size\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(9, 6))  # Adjust the figure size for the journal aspect ratio\n",
    "\n",
    "    from matplotlib.cm import get_cmap\n",
    "    # colors = get_cmap(\"Set1\", len(R_vals)+1)\n",
    "    colors =  np.array([\"#fa0707\", \"#363636\", \"#30fc03\", \"#0207fa\",\"#f757f2\",\"#0dffef\"])#, \"#f757f2\", \"#0dffef\", \"#ffaa0d\"])\n",
    "    ecolors = np.array([\"#960404\", \"#050505\", \"#1c9701\", \"#01037d\", \"#f757e3\",\"#0dff13\"])\n",
    "    markers = [\"o\", \"v\", \"^\", \"s\", \"P\", \"X\"]\n",
    "\n",
    "    inset = False\n",
    "    if inset == True:\n",
    "        from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "        inset_ax = inset_axes(ax1, width=\"40%\", height=\"50%\", loc='upper left')\n",
    "        inset_ax.set_xlim(0.92, 1.21)  # Zoom in on the region of interest\n",
    "        # inset_ax.set_xlim(0.76, 1.06)  # Zoom in on the region of interest\n",
    "        inset_ax.set_ylim(9.9/48, 12.1/48)\n",
    "        # inset_ax.set_ylim(8.9/48, 10.1/48)\n",
    "        inset_ax.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        inset_ax.tick_params(left=False, right=False, top=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "    # S_times_R = 160000\n",
    "    # M_vals = np.array([194,155,191,184,187,196])\n",
    "    M_vals = np.array([199,199,198,196])\n",
    "    # M_vals = np.array([190,194,191,184,190])\n",
    "    # S_vals = np.array([200,100,50,20,10])\n",
    "    S_vals = 160000/R_vals\n",
    "    e_vals = np.full(len(R_vals),0.05)\n",
    "    # e_vals = np.array([0.1,0.1,0.05,0.15,0.1])\n",
    "    # Plot the first dataset with error bars\n",
    "    for i in range(len(R_vals)):\n",
    "        label = fr\"R = {R_vals[i]}, S = {S_vals[i]}, M = {M_vals[i]}\"#, $\\epsilon$ = {e_vals[i]}\"\n",
    "        ax1.errorbar(beta_model, unbiased_observables[:,i], standard_errors[:,i], \n",
    "                    linewidth=0.1, elinewidth=0.8, \n",
    "                    marker=markers[i], markersize=1.5, \n",
    "                    color='none', ecolor=ecolors[i], \n",
    "                    mec = colors[i], mew = 0.5,\n",
    "                    label=label)\n",
    "        if inset == True:\n",
    "            inset_ax.errorbar(beta_model, unbiased_observables[:,i], standard_errors[:,i], \n",
    "                    linewidth=0.1, elinewidth=0.8, \n",
    "                    marker=markers[i], markersize=1, \n",
    "                    color='none', ecolor=ecolors[i], \n",
    "                    mec = colors[i], mew = 0.5,\n",
    "                    label=label)\n",
    "\n",
    "\n",
    "    # Axis labels\n",
    "    ax1.set_xlabel(r\"Inverse temperature $\\beta$\", fontsize=12)\n",
    "    ax1.set_ylabel(f\"{header}\", fontsize=12)\n",
    "\n",
    "    # Limits and grid\n",
    "    ax1.set_xlim(0.2, 1.3)\n",
    "    ax1.set_xlim(0.9, 1.15)\n",
    "    ax1.set_ylim(0,3)\n",
    "    if quantity == 11:\n",
    "        ax1.set_ylim(0.15,0.26)\n",
    "\n",
    "    ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Title with LaTeX formatting\n",
    "    ax1.set_title(rf\"Unbiased Estimator with Standard Error for {header}\" +f\"\\n\"\n",
    "                + rf\"$\\kappa = {kappa}$, $L = {L}$\", fontsize=11)\n",
    "\n",
    "    # Legend\n",
    "    ax1.legend(loc='upper left', frameon=True, markerscale = 4)\n",
    "\n",
    "    from fractions import Fraction\n",
    "    if quantity == 11:\n",
    "        ax1.hlines(y = np.arange(((L/8)+1)/L, ((L/4)+1)/L, 1/L), xmin = 0, xmax = 2.5, linewidth = 1, linestyle = 'dashed', alpha = 0.6, color = \"black\")\n",
    "        # ax1.set_title(rf\"Unbiased Estimator with Standard Error for Dominant Wavenumber\" +f\"\\n\"\n",
    "        #           + rf\"$\\kappa = {kappa}$, $L = {L}$, {modestr}\", fontsize=11)\n",
    "        ax1.set_ylabel(r\"Wavenumber$/2\\pi$\", fontsize=12)\n",
    "        if inset == True:\n",
    "            inset_ax.hlines(y = np.arange(((L/8)+1)/L, ((L/4)+1)/L, 1/L), xmin = 0, xmax = 2.5, linewidth = 1, linestyle = 'dashed', alpha = 0.6, color = \"black\")\n",
    "            ax1.set_yticks(ticks = np.arange(((L/8)+1)/L, ((L/4)+1)/L, 1/L), labels = (f'{str(int(i*L))}/{str(L)}' for i in np.arange(((L/8)+1)/L, ((L/4)+1)/L, 1/L)))\n",
    "    # Optimize layout and save\n",
    "\n",
    "    # ax1.text(x = 0.325, y = 1.6, s = r\"$\\Delta \\beta = 0.005$\", bbox = dict(facecolor='yellow', alpha=0.5))\n",
    "    # ax1.text(x = 0.55, y = 1.6, s = r\"$\\Delta \\beta = 0.0005$\",bbox = dict(facecolor='yellow', alpha=0.5))\n",
    "    # ax1.vlines(x = [0.5], ymin = 0, ymax = 4, linestyle = 'dashed', alpha = 0.5)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    from datetime import date\n",
    "    datestr = date.today().strftime(\"%d%b%y\")\n",
    "    descriptor = f\"{header}-{modestr}\"\n",
    "    print(datestr)\n",
    "    if kappa == 0.6:\n",
    "        kappafilestr = \"k-0-6\"\n",
    "    elif kappa == 0:\n",
    "        kappafilest = \"k-0\"\n",
    "    plt.savefig(f\"/Users/shanekeiser/Documents/ANNNI/figures/{datestr}_{descriptor}_{kappafilestr}_L-{L}_R-comparison.png\", dpi=300)  # Save in high resolution\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
